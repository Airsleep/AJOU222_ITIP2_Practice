{"cells":[{"cell_type":"markdown","metadata":{"id":"gQaogG5gAt_j"},"source":["# CNN 실습 문제 1: ResNeXt, WideResNet 적용하기\n","\n","\n","## 1. 문제 설명\n","1. ResNet18 모델의 검증 결과와 ResNeXt18 (32x4d) 모델의 검증 결과를 비교.\n","2. ResNet18 모델의 검증 결과와 WRN-18-2-bottleneck 모델의 검증 결과를 비교.\n","3. 조건: 주어진 노트북의 다른 hyperparameter는 변경하지 말고 모델만 변경할 것. 실습 과제 제출시에 사용한 모델과 모든 로그가 담겨 있는 노트북 제출. 모델은 Basic block이 아닌 주어진 Bottleneck block을 사용할 것.\n","\n","## 2. 목차\n","1. 필요한 패키지 불러오기 및 parameter 구성하기\n","2. CIFAR10 데이터 가져오기\n","3. Trainloader 이미지 살펴보기\n","4. ResNet, (\\*) ResNeXt, (**) WideResNet 정의\n","5. 모델 학습 및 검증\n","\n","## 3. 참고자료\n","1. (ResNet) Deep Residual Learning for Image Recognition, CVPR, 2016 [[ArXiv](https://arxiv.org/pdf/1512.03385)]\n","2. (*) (ResNeXt) Aggregated Residual Transformations for Deep Neural Networks, CVPR, 2017 [[ArXiv](https://arxiv.org/pdf/1611.05431)]\n","3. (**) (WideResNet) Wide Residual Networks, ArXiv, 2016 [[ArXiv](https://arxiv.org/pdf/1605.07146)]\n","4. Referential model code [[torchvision.models](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py)]"]},{"cell_type":"markdown","metadata":{"id":"A6B0L8JnBJZU"},"source":["## 1. 필요한 패키지 불러오기 및 Parameter 구성하기"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":447,"status":"ok","timestamp":1668051494679,"user":{"displayName":"정민규","userId":"17160246228902515539"},"user_tz":-540},"id":"Hg_YNZlCNogO","outputId":"0c74a16d-d13d-4ad6-bb94-810b808dde5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import pickle\n","import time\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","from torchsummary import summary\n","# Seed 설정 --> 코드를 돌릴때 random값을 동일하게 해주기 위해\n","random.seed(10)\n","np.random.seed(123)\n","\n","# GPU사용을 위한 설정\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","# 모델 파라미터 설정\n","config = {'Cifar10_stats': [[0.49139965, 0.48215845, 0.4465309],\n","                            [0.20220213, 0.19931543, 0.20086348]],\n","          'batch_size'  : 16,\n","          'worker'      : 2,\n","          'epochs'      : 5,\n","          'momentum'    : 0.9,\n","          'lr_decay'    : 0.0005,\n","          'SGD_lr'      : 0.01,\n","          'Adam_lr'     : 0.001,\n","          }"]},{"cell_type":"markdown","metadata":{"id":"jDC7z8GXCggj"},"source":["## 2. CIFAR10 데이터 가져오기\n","CIFAR10의 정규화를 위해 직접 CIFAR10 데이터의 평균과 표준편차를 구해서 Train/Test 데이터셋에 정규화를 적용한다. "]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1704,"status":"ok","timestamp":1668051496381,"user":{"displayName":"정민규","userId":"17160246228902515539"},"user_tz":-540},"id":"3zUe6aFjZNN9","outputId":"f40fb24d-b306-439b-a839-c2af30ec25ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"519b8adb59184c57a0f1aa6df4f172b5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n","Trainset 개수: 50000, Testset 개수: 10000\n"]}],"source":["trainset = torchvision.datasets.CIFAR10(root='./data', train = True, download = True, transform = transforms.ToTensor())\n","testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transforms.ToTensor())\n","print(f\"Trainset 개수: {len(trainset)}, Testset 개수: {len(testset)}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":19182,"status":"ok","timestamp":1668051515561,"user":{"displayName":"정민규","userId":"17160246228902515539"},"user_tz":-540},"id":"jj639FeZZqdE"},"outputs":[],"source":["# To normalize the dataset, calculate the mean and std\n","train_meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in trainset]\n","train_stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in trainset]\n","\n","train_meanR = np.mean([m[0] for m in train_meanRGB])\n","train_meanG = np.mean([m[1] for m in train_meanRGB])\n","train_meanB = np.mean([m[2] for m in train_meanRGB])\n","train_stdR = np.mean([s[0] for s in train_stdRGB])\n","train_stdG = np.mean([s[1] for s in train_stdRGB])\n","train_stdB = np.mean([s[2] for s in train_stdRGB])"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1668051515561,"user":{"displayName":"정민규","userId":"17160246228902515539"},"user_tz":-540},"id":"NNSz9dUKfltu","outputId":"a2c20bd0-c464-4dd3-e579-4528ab429ae3"},"outputs":[{"name":"stdout","output_type":"stream","text":["CIFAR10_MEAN: 0.49139965 0.48215845 0.4465309\n","CIFAR10_STD: 0.20220213 0.19931543 0.20086348\n"]}],"source":["print(\"CIFAR10_MEAN:\",train_meanR, train_meanG, train_meanB) # Cifar10_stats -> mean\n","print(\"CIFAR10_STD:\",train_stdR, train_stdG, train_stdB) # Cifar10_stats-> std"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1668051515561,"user":{"displayName":"정민규","userId":"17160246228902515539"},"user_tz":-540},"id":"3uph1HO4Nu-O","outputId":"caa7015d-7fb3-45f8-8898-a70d462b1ac6"},"outputs":[{"name":"stdout","output_type":"stream","text":["['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"]}],"source":["train_transforms = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(*config['Cifar10_stats']), # mean = Cifar10_stats[0], std = Cifar10_stats[1]\n","])\n","\n","test_transforms = transforms.Compose([\n","    transforms.Resize(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(*config['Cifar10_stats']), # mean = Cifar10_stats[0], std = Cifar10_stats[1]\n","])\n","\n","# apply transform\n","trainset.transform = train_transforms\n","testset.transform = test_transforms\n","\n","# Data Loader\n","trainloader = DataLoader(trainset, batch_size = config['batch_size'], shuffle = True, num_workers = config['worker'])\n","testloader = DataLoader(testset, batch_size = config['batch_size'], shuffle = False, num_workers = config['worker'])\n","\n","# Class_name 저장\n","with open('./data/cifar-10-batches-py/batches.meta', 'rb') as f:\n","    batches_meta = pickle.load(f, encoding = 'latin1')\n","classes_name = list(batches_meta[sorted(list(batches_meta.keys()))[0]]) # airplane, automobile, ..., truck\n","print(classes_name)"]},{"cell_type":"markdown","metadata":{"id":"6U3Om6lkEQ5r"},"source":["## 3. trainloader 이미지 살펴보기\n","\n","CIFAR10데이터 가져오기에서 만든 trainloader에 이미지가 어떻게 저장되어있는지 이미지와 라벨을 같이 확인해본다."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":361},"executionInfo":{"elapsed":2583,"status":"ok","timestamp":1668051518141,"user":{"displayName":"정민규","userId":"17160246228902515539"},"user_tz":-540},"id":"2xUbzcSINvJu","outputId":"675bd25f-6f11-4c30-8694-167ded040efe"},"outputs":[{"ename":"AttributeError","evalue":"'_MultiProcessingDataLoaderIter' object has no attribute 'next'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn [11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# trainloader의 이미지 확인\u001b[39;00m\n\u001b[1;32m      5\u001b[0m dataiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(trainloader)\n\u001b[0;32m----> 6\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mdataiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m()\n\u001b[1;32m      7\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m), dpi \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      8\u001b[0m ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: '_MultiProcessingDataLoaderIter' object has no attribute 'next'"]}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# trainloader의 이미지 확인\n","dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n","fig = plt.figure(figsize = (15, 5), dpi = 100)\n","ax = fig.add_subplot(1,1,1)\n","ax.imshow(torchvision.utils.make_grid(images, normalize = True).permute(1, 2, 0))\n","plt.show()\n","\n","# 해당 이미지의 label확인\n","for i in range(len(images)):\n","    if (i+1)%8==0:\n","        print(f'{i+1}: {classes_name[labels[i]]}', end = '\\n')\n","    else:\n","        if len(classes_name[labels[i]]) >= 6:\n","            print(f'{i+1}: {classes_name[labels[i]]}', end = '\\t')\n","        else:\n","            print(f'{i+1}: {classes_name[labels[i]]}', end = '  \\t')"]},{"cell_type":"markdown","metadata":{"id":"TrCinkAfDlE-"},"source":["## 4. 모델 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1668051518142,"user":{"displayName":"정민규","userId":"17160246228902515539"},"user_tz":-540},"id":"rFlZDR6-Nz0I"},"outputs":[],"source":["# class BottleNeck(nn.Module):\n","#     \"\"\" BottleNeck Block Definition\n","#     (hint 1): modify this class __init__()\n","#     \"\"\"\n","#     expansion = 4\n","#     def __init__(self, in_channels, out_channels, stride=1):\n","#         super().__init__()\n","#         self.residual_function = nn.Sequential(\n","#             nn.Conv2d(in_channels, out_channels, kernel_size=1, bias = False),\n","#             nn.BatchNorm2d(out_channels),\n","#             nn.ReLU(),\n","#             nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size = 3, padding = 1, bias = False),\n","#             nn.BatchNorm2d(out_channels),\n","#             nn.ReLU(),\n","#             nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size = 1, bias = False),\n","#             nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n","#         )\n","\n","#         self.relu = nn.ReLU()\n","#         self.shortcut = nn.Sequential()\n","\n","#         if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n","#             self.shortcut = nn.Sequential(\n","#                 nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride = stride, kernel_size = 1, bias = False),\n","#                 nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n","#             )\n","    \n","#     def forward(self, x):\n","#         x = self.residual_function(x) + self.shortcut(x)\n","#         x = self.relu(x)\n","#         return x\n","\n","# class ResNet(nn.Module):\n","#     \"\"\"ResNet Model Definition\n","#     (hint 2): modify this class __init__()\n","#     \"\"\"\n","#     # block: BottleNeck, num_block: [2,2,2,2]\n","#     def __init__(self, block, num_block, num_classes=10):\n","#         super().__init__()\n","\n","#         self.in_channels = 64\n","\n","#         self.conv1 = nn.Sequential(\n","#             nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias = False),\n","#             nn.BatchNorm2d(64),\n","#             nn.ReLU(),\n","#             nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","#         )\n","\n","#         self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n","#         self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n","#         self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n","#         self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n","\n","#         self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n","#         self.fc = nn.Linear(512 * block.expansion, num_classes)\n","        \n","#     def _make_layer(self, block, out_channels, num_blocks, stride):\n","#         strides = [stride] + [1] * (num_blocks - 1)\n","#         layers = []\n","#         for stride in strides:\n","#             layers.append(block(self.in_channels, out_channels, stride))\n","#             self.in_channels = out_channels * block.expansion\n","        \n","#         return nn.Sequential(*layers)\n","\n","#     def forward(self, x):\n","#         output = self.conv1(x)\n","#         output = self.conv2_x(output)\n","#         x = self.conv3_x(output)\n","#         x = self.conv4_x(x)\n","#         x = self.conv5_x(x)\n","#         x = self.avg_pool(x)\n","#         x = x.view(x.size(0), -1)\n","#         x = self.fc(x)\n","#         return x\n","\n","\n","# class BottleNeck_ResNeXt(nn.Module):\n","#     \"\"\" BottleNeck Block Definition\n","#     (hint 1): modify this class __init__()\n","#     \"\"\"\n","#     expansion = 4\n","#     cardinarity = 32\n","#     base_width = 64\n","#     depth = 4\n","\n","#     def __init__(self, in_channels, out_channels, stride=1, cardinarity=32, base_width=64, depth=4):\n","#         super().__init__()\n","#         # self.cardinarity = cardinarity\n","#         # self.base_width = base_width\n","#         # self.depth = int(depth * out_channels / self.base_witdh)\n","#         cmuld = int(BottleNeck_ResNeXt.cardinarity * (BottleNeck_ResNeXt.depth * out_channels/BottleNeck_ResNeXt.base_width))\n","\n","#         self.residual_function = nn.Sequential(\n","#             # nn.Conv2d(in_channels, self.cmuld, kernel_size=1, bias = False),\n","#             # nn.BatchNorm2d(self.cmuld),\n","#             # nn.ReLU(),\n","#             # nn.Conv2d(self.cmuld, self.cmuld, stride=stride, groups=self.cardinarity, padding = 1, bias = False),\n","#             # nn.BatchNorm2d(self.cmuld),\n","#             # nn.ReLU(),\n","#             # nn.Conv2d(self.cmuld, out_channels * BottleNeck.expansion, kernel_size = 1, bias = False),\n","#             # nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n","#             nn.Conv2d(in_channels, cmuld, kernel_size=1, stride = 1, padding = 0, bias = False),\n","#             nn.BatchNorm2d(cmuld),\n","#             nn.ReLU(),\n","#             nn.Conv2d(cmuld, cmuld, stride=stride, groups=BottleNeck_ResNeXt.cardinarity, kernel_size = 3, padding = 1, bias = False),\n","#             nn.BatchNorm2d(cmuld),\n","#             nn.ReLU(),\n","#             nn.Conv2d(cmuld, out_channels * BottleNeck_ResNeXt.expansion, kernel_size = 1, stride =1, padding = 0, bias = False),\n","#             nn.BatchNorm2d(out_channels * BottleNeck_ResNeXt.expansion),\n","#         )\n","\n","#         self.relu = nn.ReLU()\n","#         self.shortcut = nn.Sequential()\n","\n","\n","#         if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n","#             self.shortcut = nn.Sequential(\n","#                 nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride = stride, kernel_size = 1, padding=0, bias = False),\n","#                 nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n","#             )\n","    \n","#     def forward(self, x):\n","#         x = self.residual_function(x) + self.shortcut(x)\n","#         x = self.relu(x)\n","#         return x\n","\n","# class ResNeXt(nn.Module):\n","#     \"\"\"ResNet Model Definition\n","#     (hint 2): modify this class __init__()\n","#     \"\"\"\n","#     # block: BottleNeck, num_block: [2,2,2,2]\n","#     def __init__(self, block, num_block, num_classes=10):\n","#         super().__init__()\n","\n","#         self.in_channels = 64\n","\n","#         self.conv1 = nn.Sequential(\n","#             nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias = False),\n","#             nn.BatchNorm2d(64),\n","#             nn.ReLU(),\n","#             nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","#         )\n","\n","#         self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n","#         self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n","#         self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n","#         self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n","\n","#         self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n","#         self.fc = nn.Linear(512 * block.expansion, num_classes)\n","        \n","#     def _make_layer(self, block, out_channels, num_blocks, stride):\n","#         strides = [stride] + [1] * (num_blocks - 1)\n","#         layers = []\n","#         for stride in strides:\n","#             layers.append(block(self.in_channels, out_channels, stride))\n","#             self.in_channels = out_channels * block.expansion\n","        \n","#         return nn.Sequential(*layers)\n","\n","#     def forward(self, x):\n","#         output = self.conv1(x)\n","#         output = self.conv2_x(output)\n","#         x = self.conv3_x(output)\n","#         x = self.conv4_x(x)\n","#         x = self.conv5_x(x)\n","#         x = self.avg_pool(x)\n","#         x = x.view(x.size(0), -1)\n","#         x = self.fc(x)\n","#         return x\n","\n","\n","\n","# class BottleNeck_WRN(nn.Module):\n","#     \"\"\" BottleNeck Block Definition\n","#     (hint 1): modify this class __init__()\n","#     \"\"\"\n","\n","#     def __init__(self, in_channels, out_channels, stride=1):\n","#         super().__init__()\n","#         self.residual_function = nn.Sequential(\n","#             nn.BatchNorm2d(in_channels),\n","#             nn.ReLU(),\n","#             nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias = False),\n","#             nn.BatchNorm2d(out_channels),\n","#             nn.ReLU(),\n","#             nn.Dropout(),\n","#             nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias = False)\n","#         )\n","\n","#         # self.relu = nn.ReLU()\n","#         self.shortcut = nn.Sequential()\n","\n","#         if stride != 1 or in_channels != out_channels:\n","#             self.shortcut = nn.Sequential(\n","#                 nn.Conv2d(in_channels, out_channels, stride = stride, kernel_size = 1, padding=0, bias = False),\n","#                 nn.BatchNorm2d(out_channels)\n","#             )\n","    \n","#     def forward(self, x):\n","#         x = self.residual_function(x) + self.shortcut(x)\n","#         # x = self.relu(x)\n","#         return x\n","\n","# class WRN(nn.Module):\n","#     \"\"\"ResNet Model Definition\n","#     (hint 2): modify this class __init__()\n","#     \"\"\"\n","#     def __init__(self, block, depth, k, num_classes=10):\n","#         super().__init__()\n","        \n","#         self.N = int((depth-4)/6)\n","#         self.in_channels = 16\n","\n","#         self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1, bias = False)\n","#         self.conv2_x = self._make_layer(block, 16*k, self.N, 1)\n","#         self.conv3_x = self._make_layer(block, 32*k, self.N, 2)\n","#         self.conv4_x = self._make_layer(block, 64*k, self.N, 2)\n","#         self.bn = nn.BatchNorm2d(64*k)\n","#         self.relu = nn.ReLU()\n","#         self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n","#         self.fc = nn.Linear(64 * k, num_classes)\n","        \n","#     def _make_layer(self, block, out_channels, num_blocks, stride):\n","#         strides = [stride] + [1] * (num_blocks - 1)\n","#         layers = []\n","#         for stride in strides:\n","#             layers.append(block(self.in_channels, out_channels, stride))\n","#             self.in_channels = out_channels\n","        \n","#         return nn.Sequential(*layers)\n","\n","#     def forward(self, x):\n","#         output = self.conv1(x)\n","#         output = self.conv2_x(output)\n","#         x = self.conv3_x(output)\n","#         x = self.conv4_x(x)\n","#         x = self.bn(x)\n","#         x = self.relu(x)\n","#         x = self.avg_pool(x)\n","#         x = x.view(x.size(0), -1)\n","#         x = self.fc(x)\n","#         return x\n","\n","# def ResNet18():\n","#     return ResNet(BottleNeck, [2, 2, 2, 2])\n","\n","# def ResNeXt18():\n","#     \"\"\"Define your model here\"\"\"\n","#     # cardinarity: 32, depth: 4\n","#     return ResNeXt(BottleNeck_ResNeXt, [3, 4, 6, 3])\n","\n","# def WRN18_2():\n","#     \"\"\"Define your model here\"\"\"\n","#     # WRN-18-2-bottleneck\n","#     return WRN(BottleNeck_WRN, depth=40, k=10)\n","\n","class BottleNeck(nn.Module):\n","    \"\"\" BottleNeck Block Definition\n","    (hint 1): modify this class __init__()\n","    \"\"\"\n","    expansion = 4\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","        self.residual_function = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias = False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size = 3, padding = 1, bias = False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size = 1, bias = False),\n","            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n","        )\n","\n","        self.relu = nn.ReLU()\n","        self.shortcut = nn.Sequential()\n","\n","        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride = stride, kernel_size = 1, bias = False),\n","                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n","            )\n","    \n","    def forward(self, x):\n","        x = self.residual_function(x) + self.shortcut(x)\n","        x = self.relu(x)\n","        return x\n","\n","class ResNet(nn.Module):\n","    \"\"\"ResNet Model Definition\n","    (hint 2): modify this class __init__()\n","    \"\"\"\n","    # block: BottleNeck, num_block: [2,2,2,2]\n","    def __init__(self, block, num_block, num_classes=10):\n","        super().__init__()\n","\n","        self.in_channels = 64\n","\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias = False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","        )\n","\n","        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n","        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n","        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n","        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n","\n","        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","        \n","    def _make_layer(self, block, out_channels, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_channels, out_channels, stride))\n","            self.in_channels = out_channels * block.expansion\n","        \n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        output = self.conv1(x)\n","        output = self.conv2_x(output)\n","        x = self.conv3_x(output)\n","        x = self.conv4_x(x)\n","        x = self.conv5_x(x)\n","        x = self.avg_pool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x\n","\n","\n","def ResNet18():\n","    return ResNet(BottleNeck, [2, 2, 2, 2])\n","\n","def ResNeXt18():\n","    \"\"\"Define your model here\"\"\"\n","    # cardinarity: 32, depth: 4\n","    return ResNet(BottleNeck, [3, 4, 6, 3])\n","\n","def WRN18_2():\n","    \"\"\"Define your model here\"\"\"\n","    # WRN-18-2-bottleneck\n","    return ResNet(BottleNeck, depth=40, k=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1668051518142,"user":{"displayName":"정민규","userId":"17160246228902515539"},"user_tz":-540},"id":"SdaJL0US2SGG","outputId":"95b41b1d-abf0-434c-f394-a82ed9d8f758"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1, 1]\n"]}],"source":["model_wrn18_2 = WRN18_2()\n","summary(model_wrn18_2, (3, 64, 64), device=device.type)"]},{"cell_type":"markdown","metadata":{"id":"SykHBlc9DiVN"},"source":["## 5. 모델 학습 및 검증"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11951440,"status":"ok","timestamp":1668063469579,"user":{"displayName":"정민규","userId":"17160246228902515539"},"user_tz":-540},"id":"9XejZ3gtTWEX","outputId":"ce3e958a-727c-4edd-bdc6-44df18baf75d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1/5, train_loss: 0.1115, time:1m 45s\n","Epoch: 2/5, train_loss: 0.0774, time:1m 40s\n","Epoch: 3/5, train_loss: 0.0614, time:1m 41s\n","Epoch: 4/5, train_loss: 0.0506, time:1m 41s\n","Epoch: 5/5, train_loss: 0.0450, time:1m 40s\n","Finished Training of resnet18\n","Accuracy of the resnet18 on the 10000 test images: 74.65%\n","Epoch: 1/5, train_loss: 0.1131, time:2m 36s\n","Epoch: 2/5, train_loss: 0.0707, time:2m 36s\n","Epoch: 3/5, train_loss: 0.0527, time:2m 37s\n","Epoch: 4/5, train_loss: 0.0437, time:2m 36s\n","Epoch: 5/5, train_loss: 0.0380, time:2m 40s\n","Finished Training of resnext18\n","Accuracy of the resnext18 on the 10000 test images: 79.15%\n","Epoch: 1/5, train_loss: 0.1041, time:35m 49s\n","Epoch: 2/5, train_loss: 0.0751, time:35m 50s\n","Epoch: 3/5, train_loss: 0.0636, time:35m 50s\n","Epoch: 4/5, train_loss: 0.0569, time:35m 50s\n","Epoch: 5/5, train_loss: 0.0519, time:35m 49s\n","Finished Training of wrn-18-2-bottleneck\n","Accuracy of the wrn-18-2-bottleneck on the 10000 test images: 70.47%\n"]}],"source":["def get_model(model_name):\n","    if model_name == 'resnet18':\n","        return ResNet18()\n","    elif model_name == 'resnext18':\n","        return ResNeXt18()\n","    elif model_name == 'wrn-18-2-bottleneck':\n","        return WRN18_2()\n","    else:\n","        raise Exception(f\"{model_name} is not supported yet\")\n","\n","\n","for model_name in ['resnet18', 'resnext18', 'wrn-18-2-bottleneck']:\n","    model = get_model(model_name).to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(params=model.parameters(), lr = config['SGD_lr'], momentum= config['momentum'], weight_decay=config['lr_decay'])\n","\n","    for epoch in range(config['epochs']):  # loop over the dataset multiple times\n","\n","        running_loss = 0.0\n","        start_time = time.time()\n","        for inputs, labels in trainloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            output = model(inputs)\n","            loss = criterion(output, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","            #Time\n","            end_time = time.time()\n","            time_taken = end_time - start_time\n","            time_taken = str(time_taken/60).split('.')\n","            \n","        print('Epoch: {}/{}, train_loss: {:.4f}, time:{}m {}s'.format(epoch + 1, config['epochs'], running_loss / len(trainset), time_taken[0], time_taken[1][:2]))\n","\n","    print(f'Finished Training of {model_name}')\n","\n","    #Testing Accuracy\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data[0].to(device), data[1].to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    print(f'Accuracy of the {model_name} on the 10000 test images: {100 * correct / total:.2f}%')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3.8.13 ('newenv')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"2ea857b7e451003d2e63c85ccd5dcdbb10f4229faf903ccd8fe672ae4e1d0ef6"}}},"nbformat":4,"nbformat_minor":0}
